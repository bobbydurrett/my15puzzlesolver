Working on a 15 puzzle solver in Python for Rosetta Code:

http://rosettacode.org/wiki/15_puzzle_solver

astar.py is my A* algorithm attempt.
stuck on about 3 seconds for a 21 move puzzle.
not fast enough for the RC 52 move puzzle.

seems to hit 2 gigabyte limit on 30 move puzzle.
Could try 64 bit python to use more memory
or try optimizing memory usage.

seems to hit the 2 gig limit at about 1.6 million 
positions examined.

postest.py - created list of 5 million positions
in 2 gig of memory. Need to test inserting
this many in the priority queue.

idastar.py is my IDA* attempt. This is on the 
back burner while I'm working on my A* version.

Got the 30 move puzzle to run with 64 bit windows
version of Python 3.7.1

1700000 positions examined
1800000 positions examined
1900000 positions examined
2000000 positions examined
2100000 positions examined
2200000 positions examined
2300000 positions examined

Path length = 30

Path using rlud:

ddluuuldlurrdrdlllurrrullddrdr

Run time in seconds: 168.38073773099998

Blew up at about 8 gig memory on RC example:

19100000 positions examined
19200000 positions examined
19300000 positions examined
19400000 positions examined
19500000 positions examined
19600000 positions examined
Traceback (most recent call last):
  File "C:\bobby\15puzzlesolver\my15puzzlesolver\testone.py", line 87, in <module>
  File "C:\bobby\15puzzlesolver\my15puzzlesolver\astar.py", line 572, in a_star
  File "C:\bobby\15puzzlesolver\my15puzzlesolver\astar.py", line 136, in neighbors
  File "C:\bobby\15puzzlesolver\my15puzzlesolver\astar.py", line 36, in __init__
MemoryError

over 19 million nodes.

Updated postest.py to include priority queue pushes.

Number of positions to create? 5000000

5000000 successfully created.

Run time in seconds: 29.045173822000002

29 seconds to push and create 5,000,000 positions.

started intpos.py

did quick heuristics test htest.py.

code golf example had 43 for 52 move position and mine had 38.

Both had 13 for 21 move position.

tested using intpos.py instead of list of lists position:

C:\todoitems\rosettacode\15puzzlesolver\my15puzzlesolver>postest.py

Number of positions to create? 5000000

5000000 successfully created.

Run time in seconds: 24.96709779

Hit enter to continue:

C:\todoitems\rosettacode\15puzzlesolver\my15puzzlesolver>intpostest.py

Number of positions to create? 5000000

5000000 successfully created.

Run time in seconds: 10.893528313000001

Hit enter to continue:

11 seconds instead of 25 to load 5 million positions in the queue.

Did 12 million in 26 seconds.

C:\todoitems\rosettacode\15puzzlesolver\my15puzzlesolver>intpostest.py

Number of positions to create? 12000000

12000000 successfully created.

Run time in seconds: 26.476382996999998

Hit enter to continue:

So, I guess intpos.py takes less memory than the list based version.

C:\todoitems\rosettacode\15puzzlesolver\my15puzzlesolver>postest.py

Number of positions to create? 12000000
Traceback (most recent call last):
  File "C:\todoitems\rosettacode\15puzzlesolver\my15puzzlesolver\postest.py", line 23, in <module>
    [13,  8,  5,  2]]))
  File "C:\todoitems\rosettacode\15puzzlesolver\my15puzzlesolver\astar.py", line 181, in push
    heapq.heappush(self.qheap,new_object)
MemoryError

Checked code golf version:

before walking distance d=2
after walking distance d=42
before walking distance d=2

Looks like walking distance (manhattan distance) = 40 for
RC start position.

Also it seems to do both x and y direction linear conflicts.

mine has manhattan distance 36.

C:\todoitems\rosettacode\15puzzlesolver\my15puzzlesolver>htest.py
manhattan distance = 36
with linear conflicts distance = 38
38

Looks like difference is that it includes 0

tried changing my heuristic but then for 21 heuristic is 18.

Not sure if including 0 is right.

Next step is to change position to use intpos approach.

May not solve entire problem but it does use less 
memory.

need to finish intpos.py and unit test each function.

updated intastar.py to use intpos.py 

It is slower than with the list of lists version for some reason
but uses a lot less memory. This is with 32 bit python:

1900000 positions examined
2000000 positions examined
2100000 positions examined
2200000 positions examined
2300000 positions examined

Path length = 30

Path using rlud:

ddluuuldlurrdrdlllurrrullddrdr

Run time in seconds: 314.350291496

python -m cProfile -s cumtime inttestone.py > cumtimeprofile.txt

python -m cProfile -s time inttestone.py > timeprofile.txt

Maybe try converting astar.py to use tuples where possible?

htest2.py

trying to test heuristic against a bunch of positions that
are generated.

My set isn't working it seems. two Position objects with same tiles
are not eliminated by the set. yuck!

Modified position to define hash function.

Should be able to convert astar to use tuples and hash with them or
something like that. Must have had a ton of duplicates in the PriorityQueue.

RC test is running for a while but hasn't filled up memory so that's nice.

tupastar.py seems pretty fast.

Messing with __eq__ made a huge difference.

Need to check priority queue and set implementation.

also astar logic.

tupastar.py much faster:

C:\todoitems\rosettacode\15puzzlesolver\my15puzzlesolver>tuptestone.py

Path length = 32

Path using rlud:

ddluurdluuldlurrddllurrrullddrdr

Run time in seconds: 3.5671636529999997

Funny that it found a 32 length path instead of 30.

doing unit testing.

savedcode.py has the old row conflicts code.
consider adding back in. Can row and column conflicts 
duplicate each other? Need to carefully test
heuristic against actual path.

Also need path checker for results.

With rows added back to linear conflicts 30 is even faster:

C:\todoitems\rosettacode\15puzzlesolver\my15puzzlesolver>tuptestone.py

Path length = 32

Path using rlud:

ddluurdlurulldlurrddllurrulddrdr

Run time in seconds: 1.697198378

Verified we are using both parts of the if in the astar main function.

need to start a new test program to check all of the logic in astar.

tupastar.py is the current best astar version.

Path length = 32

Path using rlud:

ddluurdlurulldlurrddllurrulddrdr

Run time in seconds: 1.6719975219999998

This is not good. The minimum path length for this one 
is 30 but it finds a length 32 path.

So something is wrong.

30 path:

ddluuuldlurrdrdlllurrrullddrdr

32 path:

ddluurdlurulldlurrddllurrulddrdr

In __eq__

        return (self.tiles == other.tiles) and (self.fscore == other.fscore)

Had to include fscore. Looks like we have
multiple position objects with the same fscore!

https://en.wikipedia.org/wiki/A*_search_algorithm

I've shown that my heuristic is no monitone in the length 32 path example:

32
22

31
21

30
20

29
21

the length 29 path position has a higher heuristic than its neighbor instead of being 1 less or better.

So I may not be able to use astar in the format on the wikipedia article since it isn't guaranteed
to be minimal path.

Probably need to verify that my heuristic is at admissible up to 52 nodes if I can.

Probably rearchitect solution to not have closed set.

I'm thinking of using dictionaries with default values instead of storing fscore, gscore, in the node itself
or a mapping of tiles to rest of these values. That might get rid of the kludgey code in the if statement
where I switch neighbor with existing position.

Maybe just create a function that makes a new Position object but first checks a dictionary to see if they 
already exist and returns the existing one. key would be the tiles tuple of tuples. value would be the Position object.

Then get rid of the closed set. neighbors would get the existing position objects so the else can use neighbor instead
of finding inopenset.

Also save neighbors list so you don't have to recreate it.

Directory is getting cluttered. Moved all my files into a directory named old. Made a copy of tupastar.py and called it astar.py
in top directory. This is my current best version.

Looks like my heuristic isn't even admissable.

C:\bobby\15puzzlesolver\my15puzzlesolver>testheuristic.py 5

path length = 5

goal node:
(1, 2, 3, 4)
(5, 6, 7, 8)
(9, 10, 11, 12)
(13, 14, 15, 0)

heuristic value = 7

start node:
(1, 2, 3, 4)
(5, 6, 7, 8)
(9, 11, 12, 0)
(13, 10, 14, 15)


have to rewrite or fix 

def linear_conflicts(start_list,goal_list)

start_list = [ 9, 11, 12,  0]

goal_list = [ 9, 10, 11, 12]

print(linear_conflicts(start_list,goal_list))

should be 0 returns 2.

    while len(occupied_squares) > 0:
        tile_num, squares, direction, s, g = occupied_squares.pop()
        # find the tiles who intersect with this tile
        to_remove = []
        for o in range(len(occupied_squares)):
            otile_num, osquares, odirection, os, og = occupied_squares[o]
            if len(osquares&squares) > 0 and not ((os == g) and (direction == odirection)):
                print(squares)
                print(osquares)
                print(g)
                print(os)
                print(direction)
                print(odirection)
                conflicts += 1
                to_remove.append(occupied_squares[o])
        for o in to_remove:
            occupied_squares.remove(o)
 
 Maybe build 360 member dictionary linear conflict table
 which is all the possible 4 element orders of
 
 g1, g2, g3, g4, x, x
 
 treat 0 in as if it were an x when
 converting the real start node
 to these strings.
 
 Down to 1 second for length 30
 Still not sure we have monotone heuristic.
 
 C:\bobby\15puzzlesolver\my15puzzlesolver>testone.py
 
 Path length = 30
 
 Path using rlud:
 
 urrrrrlrlululrdurrdluldrruuludr
 
Run time in seconds: 1.00510262

I think build a script called rctest.py that takes the
path length as the argument.

The Rosetta Code example is a length 52 path.

If I passed say 40 to rctest.py it would apply the known
moves from the RC start position go get to the
position 40 moves away from the goal.
Then it would run astar against it.

Once I find the smallest path that runs for a couple of 
minutes I can profile it.

Also could check the RC path to see if the
heuristic is monotone along it.

could change my monotone checker to make sure we don't repeat
a position using a dictionary or set.

I guess would have to change testmonotone to do a 
breadth first expansion of the nodes to make sure
it was a shortest path and then
check for monotone heuristic along the paths.

If I did my monotone test right then my heuristic is not monotone:

path length = 6

goal node:
(1, 2, 3, 4)
(5, 6, 7, 8)
(9, 10, 11, 12)
(13, 14, 15, 0)

Pass number = 1
Pass number = 2
Pass number = 3
Pass number = 4
Pass number = 5
Pass number = 6

Not monotone

Closer to goal:

(1, 2, 3, 4)
(5, 6, 7, 8)
(9, 11, 14, 12)
(13, 10, 0, 15)

heuristic value = 5
astar path length = 5

One step farther from goal:

(1, 2, 3, 4)
(5, 6, 7, 8)
(9, 11, 14, 12)
(13, 10, 15, 0)

heuristic value = 4
astar path length = 6

This is a length 6 path and there are multiple examples where the heuristic closer to the 
goal in the shortest path has a higher h value than the next position out from the goal.
So, the Wikipedia A* pseudo code with the closedSet shouldn't be guaranteed to return the shortest path
under these conditions.

I haven't been able to find an example where my heuristic isn't admissible but 
there are many examples of where it isn't monotone or consistent.

So, I think I need to think about eliminating the closed set to make the A* code guarantee
shortest path. Or I need to switch to IDA* which should guarantee shortest path.

https://en.wikipedia.org/wiki/Iterative_deepening_A*

Here is the quote:

Like A*, IDA* is guaranteed to find the shortest path leading from the given start node to any goal node in the problem graph, if the heuristic function h is admissible

But in the A* article it says:

"the above pseudocode assumes that the heuristic function is monotonic (or consistent"

Since my a_star.py code is based ont the referenced pseudocode and I have shown examples of the heuristic not being monotonic 
we know it isn't guaranteed to return the shortest path assuming that my code correctly implemented the pseudocode.

I've testing through all optimal length 11 paths and haven't found a position that contradicts admissibility.

I think I need to try taking the closedSet out.

It should still work. But I need to make sure that we only calculate neighbors once per position
and only calculate the heuristic once per position.

The gscore could be lowered so that fscore = gscope + h is less but h will never change.

May need a better way to update the priority queue than calling heapify after
updating fscore.

spins on length 3 path. :)

C:\bobby\15puzzlesolver\my15puzzlesolver>testone.py
Traceback (most recent call last):
  File "C:\bobby\15puzzlesolver\my15puzzlesolver\testone.py", line 96, in <module>
    result = a_star(start,goal)
  File "C:\bobby\15puzzlesolver\my15puzzlesolver\astar.py", line 809, in a_star
    return reconstruct_path(current)
  File "C:\bobby\15puzzlesolver\my15puzzlesolver\astar.py", line 198, in reconstruct_path
    total_path.append(current)
MemoryError

if it is in reconstruct_path then it must have found an answer but have a loop.

funny.

(1, 2, 3, 4)
(5, 6, 7, 8)
(9, 10, 11, 12)
(13, 14, 0, 15)

(1, 2, 3, 4)
(5, 6, 7, 8)
(9, 10, 0, 12)
(13, 14, 11, 15)

(1, 2, 3, 4)
(5, 6, 7, 8)
(9, 10, 11, 12)
(13, 14, 0, 15)

(1, 2, 3, 4)
(5, 6, 7, 8)
(9, 10, 0, 12)
(13, 14, 11, 15)

Fixed length 30 to run fast:

C:\bobby\15puzzlesolver\my15puzzlesolver>python -u testone.py

Path length = 30

Path using rlud:

rrrrrlrlululruurrdluldrruuludr

Run time in seconds: 0.6177602440000001

RC example still slow.

C:\bobby\15puzzlesolver\my15puzzlesolver>python -u testone.py
100000 positions examined
200000 positions examined
300000 positions examined
400000 positions examined
500000 positions examined
600000 positions examined
700000 positions examined
800000 positions examined
900000 positions examined
Traceback (most recent call last):
  File "testone.py", line 95, in <module>
    result = a_star(start,goal)
  File "C:\bobby\15puzzlesolver\my15puzzlesolver\astar.py", line 829, in a_star
    openSet.heapify() # update priority queue heap if in
  File "C:\bobby\15puzzlesolver\my15puzzlesolver\astar.py", line 237, in heapify
    heapq.heapify(self.qheap)
  File "C:\bobby\15puzzlesolver\my15puzzlesolver\astar.py", line 62, in __lt__
    def __lt__(self, other):
KeyboardInterrupt

C:\bobby\15puzzlesolver\my15puzzlesolver>

after a fair number of minutes. only about 1000 meg memory.
seems like whenever I control-c out of these it is in heapify.

Need to build a rctest.py script that takes a number 0 - 52
which follows the RC shortest path (one of them) in reverse
and then runs a_star on that node.
Find one that runs for a few minutes and start
profiling it to optimize.

Pretty neat. Gets longer at length 45:

C:\bobby\15puzzlesolver\my15puzzlesolver>rctest.py 45
100000 positions examined

Path length = 45

Path using rlud:

rrrrullrullrddduduluuuururddluurdrdllurululrd

Run time in seconds: 81.82239044800001

python -m cProfile -s time rctest.py 45 > timeprofile.txt

Run time in seconds: 113.321280917
         256729863 function calls (256621407 primitive calls) in 113.324 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
240654573   60.693    0.000   60.693    0.000 astar.py:62(__lt__)
     2501   40.105    0.016  100.236    0.040 {built-in method _heapq.heapify}
     
Yeah. Have to come up with better way of updating the priority queue.

Maybe change our priority queue to use this kind of element:

(fscore, tiles)

We already have a dictionary that maps tiles to Position type objects.

We could just push a new (fscore, tiles) entry when fscore is lowered.

Whenever we pop from the heapq if the fscore doesn't match the current
position for tiles then discard and pop the next entry.

Could get rid of the lt, le, gt, ge stuff.  not sure about eq and hash.

Also could get rid of set and the check to see if item is in queue.

We are just pushing whenever gscore (and hence fscore) goes down.

Finally got RC start position to run in a minute:

C:\bobby\15puzzlesolver\my15puzzlesolver>testone.py
100000 positions examined
200000 positions examined
300000 positions examined
400000 positions examined
500000 positions examined
600000 positions examined
700000 positions examined
800000 positions examined

Path length = 52

Path using rlud:

rrruldluuldrurdddluulurrrdlddruldluurddlulurruldrrdd

Run time in seconds: 66.09170769100001

This is the second Rosetta Code optimal length solution.

python -m cProfile -s time testone.py > timeprofile.txt

python -m cProfile -s cumtime testone.py > cumtimeprofile.txt
